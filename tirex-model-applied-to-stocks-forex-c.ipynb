{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" !pip install torch torchvision torchaudio 'tirex-ts[notebooks,gluonts,hfdataset]' -q ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:03:56.393783Z","iopub.execute_input":"2025-11-03T11:03:56.394131Z","iopub.status.idle":"2025-11-03T11:04:01.994427Z","shell.execute_reply.started":"2025-11-03T11:03:56.394089Z","shell.execute_reply":"2025-11-03T11:04:01.992702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tirex import ForecastModel, load_model\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom matplotlib import pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:04:01.997126Z","iopub.execute_input":"2025-11-03T11:04:01.998158Z","iopub.status.idle":"2025-11-03T11:04:05.234225Z","shell.execute_reply.started":"2025-11-03T11:04:01.998117Z","shell.execute_reply":"2025-11-03T11:04:05.232924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model: ForecastModel = load_model(\"NX-AI/TiRex\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:04:05.235485Z","iopub.execute_input":"2025-11-03T11:04:05.236070Z","iopub.status.idle":"2025-11-03T11:04:06.273738Z","shell.execute_reply.started":"2025-11-03T11:04:05.236032Z","shell.execute_reply":"2025-11-03T11:04:06.272567Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Deriv API Configs","metadata":{}},{"cell_type":"markdown","source":"Deriv broker offers a handful of snthetically generated assets and I thought it would be good to see how this model performs on assets that are computer generated. Can this model pick up the under;ying patterns that power the synthetic generator?","metadata":{}},{"cell_type":"markdown","source":"To get your APP ID and token please follow this [guide](https://docs.google.com/document/d/1R0nvI5nL_-pqkqSJCsdvU0_xzFqbiwhpDr74mkuLtqo/edit?usp=sharing)","metadata":{}},{"cell_type":"code","source":"# kaggle secrets here if on kaggle\n\nfrom kaggle_secrets import UserSecretsClient\n\n# ---------------------------------------------------------\n# üîë DERIV API CONSTANTS\n# ---------------------------------------------------------\n\ntry:\n    # Initialize the secrets client\n    secrets = UserSecretsClient()\n\n    # Get the main secret string (assuming the token is stored as the primary secret)\n    DEFAULT_TOKEN = secrets.get_secret(\"deriv_api\")\n    print(\"üîë Deriv Token loaded securely.\")\n\n    # Get a custom secret key (assuming the App ID is stored as a custom key 'app_id')\n    # Note: KaggleSecrets returns strings, so it must be converted to an integer.\n    APP_ID = int(secrets.get_secret(\"deriv_app_id\"))\n    print(\"üÜî Deriv App ID loaded securely.\")\n\nexcept Exception as e:\n    # Fallback to placeholders if running outside Kaggle or secret is missing/incorrect\n    print(f\"‚ö†Ô∏è Warning: Failed to load secrets from Kaggle ({e}). Falling back to dummy values.\")\n    APP_ID = 1234\n    DEFAULT_TOKEN = \"YOUR-TOKEN-GOES-HERE\"\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:36:42.447594Z","iopub.execute_input":"2025-11-03T11:36:42.447974Z","iopub.status.idle":"2025-11-03T11:36:42.579208Z","shell.execute_reply.started":"2025-11-03T11:36:42.447949Z","shell.execute_reply":"2025-11-03T11:36:42.578026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üîó NEW DATA SOURCE: Deriv API Client for OHLC\n# =========================================================\nimport asyncio\nimport json\nimport ssl\nimport time\nimport os\nimport sys\nfrom collections import deque, Counter\nfrom decimal import Decimal, InvalidOperation\nimport certifi\nimport websockets\nfrom concurrent.futures import Future\nimport threading\n\nclass DerivOHLCFetcher:\n    \"\"\"A minimal Deriv WS client to fetch historical OHLC (candle) data.\"\"\"\n\n    def __init__(self, token: str, app_id: int):\n        self.token = token\n        self.app_id = app_id\n        self.uri = f\"wss://ws.derivws.com/websockets/v3?app_id={app_id}\"\n        # üîí Secure connection setup\n        # self.ssl_context = ssl.create_default_context(cafile=certifi.where()) \n        self.resp_queue = asyncio.Queue()\n        self.ws = None\n\n    async def connect_and_authorize(self):\n        \"\"\"Connects, authorizes, and returns the websocket object.\"\"\"\n        try:\n            print(\"üîó Connecting securely to Deriv WebSocket...\")\n            self.ws = await websockets.connect(self.uri,  open_timeout=10)\n            \n            # Start a background reader for responses\n            self.reader_task = asyncio.create_task(self._reader_loop())\n            \n            await self.ws.send(json.dumps({\"authorize\": self.token}))\n            \n            # Wait for authorization response\n            msg = await asyncio.wait_for(self.resp_queue.get(), timeout=10)\n            \n            if \"error\" in msg:\n                print(f\"üí• Authorization error: {msg['error'].get('message')}\")\n                return False\n            \n            print(f\"‚úÖ Authorized! Login ID: {msg['authorize'].get('loginid')}\")\n            return True\n        \n        except Exception as e:\n            print(f\"‚ùå Connection/Authorization failed: {e}\")\n            return False\n\n    async def _reader_loop(self):\n        \"\"\"Reads frames and pushes parsed JSON into resp_queue.\"\"\"\n        try:\n            async for raw in self.ws:\n                msg = json.loads(raw)\n                # Only queue relevant responses (authorize, error, candles)\n                if isinstance(msg, dict) and any(k in msg for k in (\"authorize\", \"error\", \"candles\")):\n                    await self.resp_queue.put(msg)\n        except Exception:\n            # üßπ Cleanly stop the reader loop\n            pass \n\n    async def fetch_ohlc(self, symbol: str, granularity: int, count: int) -> pd.DataFrame | None:\n        \"\"\"Fetches historical OHLC data and converts it to a pandas DataFrame.\"\"\"\n        if not await self.connect_and_authorize():\n            return None\n\n        # Request payload using 'ticks_history' for candles or ticks\n        # when no gransurality is supplied or is less than 60, we assume the user wants to use ticks\n        if granularity >=60:\n            payload = {\n                \"ticks_history\": symbol,\n                \"count\": count,\n                \"end\": \"latest\",\n                \"style\": \"candles\",\n                \"granularity\": granularity\n            }\n        else:\n             payload = {\n                \"ticks_history\": symbol,\n                \"count\": count,\n                \"end\": \"latest\",\n                \"style\": \"ticks\"\n                \n            }\n            \n        print(f\"‚è≥ Requesting {count} {granularity // 60}-minute candles for {symbol}...\")\n        await self.ws.send(json.dumps(payload))\n        \n        try:\n            # Wait for response\n            resp = await asyncio.wait_for(self.resp_queue.get(), timeout=30)\n            \n            if \"error\" in resp:\n                print(f\"üí• API Error on request: {resp['error'].get('message')}\")\n                return None\n            \n            # Candles data is extracted directly from the 'candles' key\n            if granularity >= 60:\n                candles = resp.get('candles', []) \n                df = pd.DataFrame(candles)\n            else:\n                candles = resp.get('prices', [])\n                times = resp.get('times',[])\n                data = {\n                        'epoch': times,\n                        'close': candles\n                    }\n                    \n                    # ‚öôÔ∏è Creating the DataFrame\n                df = pd.DataFrame(data)\n                            \n            if not candles:\n                print(\"‚ö†Ô∏è No candles returned from API.\")\n                return None\n            \n            print(f\"‚úÖ Loaded {len(candles)} candles.\")\n            \n            # Convert to DataFrame\n           \n            df['date'] = pd.to_datetime(df['epoch'], unit='s')\n            df.set_index('date', inplace=True)\n            # üéØ The model requires \"Close\" price, which is 'close' in the API response\n            df['Close'] = df['close'] \n            df.sort_index(inplace=True)\n            \n            return df[['Close']].copy()\n\n        except Exception as e:\n            print(f\"‚ùå Error during OHLC fetch: {e}\")\n            return None\n        finally:\n            # üîå Clean up connection\n            if self.ws:\n                await self.ws.close()\n            if self.reader_task:\n                 self.reader_task.cancel()\n\n\n# =========================================================\n# üí° KAGGLE/NOTEBOOK ASYNC FIX HELPER FUNCTION\n# =========================================================\n\ndef _sync_fetch_ohlc_threaded(fetcher, symbol, granularity, count):\n    \"\"\"Executes the async fetcher in a new thread with its own event loop.\"\"\"\n    print(\"‚ö†Ô∏è Bypassing main thread's running event loop (Kaggle/Jupyter fix). Fetching data in a separate thread...\")\n    \n    def run_async_in_thread(future_obj):\n        new_loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(new_loop)\n        try:\n            result = new_loop.run_until_complete(fetcher.fetch_ohlc(\n                symbol=symbol,\n                granularity=granularity,\n                count=count\n            ))\n            future_obj.set_result(result)\n        finally:\n            new_loop.close()\n\n    future = Future()\n    thread = threading.Thread(target=run_async_in_thread, args=(future,))\n    thread.start()\n    thread.join() # Wait for the thread to complete its work\n    return future.result()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:04:06.416488Z","iopub.execute_input":"2025-11-03T11:04:06.416819Z","iopub.status.idle":"2025-11-03T11:04:06.444872Z","shell.execute_reply.started":"2025-11-03T11:04:06.416792Z","shell.execute_reply":"2025-11-03T11:04:06.443755Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Core functionality","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport yfinance as yf\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom typing import List\n\n# üôà Suppress future warnings from packages like pandas/sklearn\nwarnings.filterwarnings(\"ignore\")\n\n# üíª Determine device (CPU or CUDA)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"üåç Running on device: {DEVICE}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TiREXModel:\n    \"\"\"\n    A class to fetch data, train the ResNLS model once for the given sequence length, and validate results \n    by testing multiple trading thresholds.\n    \"\"\"\n    # üì£ ACCEPTS THE LIST OF THRESHOLDS\n    def __init__(self, ticker, start_date, end_date, zoom_bars=50, prediction_length=76, future_length=51, deriv:bool=False, count:int=5000,tf:int=60): \n        # üì• Data Parameters\n        self.TICKER = ticker\n        self.START_DATE = start_date\n        self.END_DATE = end_date\n            # deriv specific\n        self.DERIV_OR_YFINANCE = deriv\n        self.GRANULARITY = tf\n        self.COUNT = count\n\n        # üíæ Data Storage\n        self.historical_data = None \n        self.data = None \n        self.close = None\n\n        self.zoom_bars: int = zoom_bars\n        self.prediction_length = prediction_length\n        self.future_length = future_length\n            \n        print(f\"\\n‚ú® Initialized ResNLS Forecaster for {self.TICKER} ({self.START_DATE} to {self.END_DATE}).\")\n       \n\n   \n\n    # --- Main Pipeline Methods (load_data, train_model, plot_loss, validate_and_plot are mostly unchanged) ---\n    def load_data(self):\n        \"\"\"Step 1: Download data and preprocess (yfinance).\"\"\"\n        print(f\"üì• Loading data for {self.TICKER}...\")\n    \n        df = yf.download(self.TICKER, start=self.START_DATE, end=self.END_DATE, progress=False)\n        if df.empty:\n            print(f\"‚ùå Error: No data found for {self.TICKER}. Exiting.\")\n            return False\n    \n        self.historical_data = df.copy()\n    \n        if \"Open\" not in df.columns:\n            print(\"‚ùå Error: 'Open' price data is missing, cannot perform prediction strategy backtest.\")\n            return False\n    \n        # ‚úÖ Keep only Open and Close columns\n        # üåü FIX/ENHANCEMENT: Explicitly use .copy() on the sliced data for self.data\n        self.data = df[[\"Open\", \"Close\"]].copy() \n        self.data.columns = [f\"{self.TICKER}_Open\", f\"{self.TICKER}_Close\"]\n    \n        # üìà Extract Close prices as the main series\n        self.close = self.data[f\"{self.TICKER}_Close\"].values.reshape(-1)\n        return True\n\n    \n    # --- Main Pipeline Methods ---\n    def load_deriv_data(self):\n            \"\"\"\n            Step 1: Fetch OHLC data from Deriv and preprocess.\n            **FIXED: Scaler is now only fitted on training data (leak-free).**\n            \"\"\"\n            print(f\"üì• Fetching {self.GRANULARITY // 60}-minute OHLC data for {self.TICKER}...\")\n            \n            # NOTE: Assumes DerivOHLCFetcher, DEFAULT_TOKEN, APP_ID, and _sync_fetch_ohlc_threaded are defined elsewhere.\n            fetcher = DerivOHLCFetcher(DEFAULT_TOKEN, APP_ID) \n            ohlc_data = None\n            \n            try:\n                ohlc_data = _sync_fetch_ohlc_threaded(\n                    fetcher, self.TICKER, self.GRANULARITY, self.COUNT\n                )\n            except Exception as e:\n                print(f\"üí• Fatal error during data fetching: {e}\")\n                return False\n    \n            if ohlc_data is None or ohlc_data.empty:\n                print(f\"‚ùå Error: No data found for {self.TICKER}. Exiting.\")\n                return False\n    \n            # üéØ Prepare data\n\n            self.close = self.data_df.values.reshape(-1)\n            return True\n\n    def plot_forecast(self, ctx, quantile_fc, real_future_values=None):\n        \"\"\"\n        Plot forecasted quantiles alongside real context and optional future values.\n        Uses a two-subplot structure: Main view and Zoomed view.\n        \"\"\"\n        \n        # Extract quantiles üéØ\n        median_forecast = quantile_fc[:, 4].numpy()\n        lower_bound = quantile_fc[:, 0].numpy()\n        upper_bound = quantile_fc[:, 8].numpy()\n\n        # üß≠ X-axis ranges (Non-overlapping logic from original code)\n        original_x = range(len(ctx))\n        # Forecast always starts right after context\n        forecast_start_index = len(ctx)\n        forecast_x = range(forecast_start_index, forecast_start_index + len(median_forecast))\n        print(f\"‚û°Ô∏è Non-overlapping forecast: forecast_x starts at {forecast_start_index}\") # ‚û°Ô∏è log message\n\n        # üé® Setup figure with two subplots\n        fig, axs = plt.subplots(2, 1, figsize=(12, 10), gridspec_kw={'height_ratios': [2, 1]})\n        fig.suptitle(f\"({self.TICKER}) üìà Forecast Visualization + üîç Zoomed (Last {self.zoom_bars} Bars + Full Forecast)\", fontsize=14, weight=\"bold\")\n\n        # -----------------------------\n        # üß© Plot 1: Main Forecast Plot (using original logic)\n        # -----------------------------\n        axs[0].plot(original_x, ctx, label=\"Ground Truth Context\", color=\"#4a90d9\")\n        if real_future_values is not None:\n            original_fut_x = range(len(ctx), len(ctx) + len(real_future_values))\n            axs[0].plot(original_fut_x, real_future_values, label=\"Ground Truth Future\", color=\"#4a90d9\", linestyle=\":\")\n        \n        # Plots the entire prediction, including the non-ground truth part\n        axs[0].plot(forecast_x, median_forecast, label=\"Forecast (Median)\", color=\"#d94e4e\", linestyle=\"--\")\n        axs[0].fill_between(\n            forecast_x, lower_bound, upper_bound, color=\"#d94e4e\", alpha=0.1, label=\"Forecast 10% - 90% Quantiles\"\n        )\n        \n        axs[0].set_xlim(left=0)\n        axs[0].legend()\n        axs[0].grid(True)\n        axs[0].set_title(\"Main Forecast View üåç\")\n        \n        # Optional connector line ü§ù\n        axs[0].plot(\n            [len(ctx) - 1, forecast_start_index],\n            [ctx[-1], median_forecast[0]],\n            color=\"#999\", linestyle=\":\", alpha=0.6\n        )\n\n        # --------------------------------\n        # üîé Plot 2: Zoomed-In Forecast - **FIXED**\n        # --------------------------------\n        \n        # 1. Calculate the starting index for the zoomed plot. \n        # This gives exactly 'self.zoom_bars' history before the prediction starts at len(ctx).\n        zoom_start = max(0, len(ctx) - self.zoom_bars)\n        \n        # 2. Define the X-axis and Y-axis data for the context part of the zoom.\n        zoom_context_x = range(zoom_start, len(ctx))\n        context_data_to_show = ctx[zoom_start:] \n\n        # 3. Define the X-axis limit for the end of the zoomed plot (full prediction).\n        zoom_end = forecast_x[-1] + 1 \n\n        # Context (Last N bars) üìä\n        axs[1].plot(zoom_context_x, context_data_to_show, color=\"#4a90d9\", label=f\"Recent Context (Last {len(context_data_to_show)})\")\n        \n        # Real future (if available) - plotted starting at len(ctx)\n        if real_future_values is not None:\n            original_fut_x = range(len(ctx), len(ctx) + len(real_future_values))\n            axs[1].plot(original_fut_x, real_future_values, color=\"#4a90d9\", linestyle=\":\", label=\"Ground Truth Future\")\n        \n        # Forecast üîÆ\n        # Plots the entire prediction, starting exactly where context ends.\n        axs[1].plot(forecast_x, median_forecast, color=\"#d94e4e\", linestyle=\"--\", label=\"Forecast (Median)\")\n        axs[1].fill_between(forecast_x, lower_bound, upper_bound, color=\"#d94e4e\", alpha=0.1, label=\"Forecast 10% - 90% Quantiles\")\n        \n        # Set X limits to ensure both history buffer and full prediction are visible.\n        axs[1].set_xlim(zoom_start, max(zoom_start, zoom_end))\n        axs[1].grid(True)\n        axs[1].legend()\n        axs[1].set_title(f\"({self.TICKER}) Zoomed Forecast Region (Last {self.zoom_bars} Bars + Full Forecast) üîç\")\n        \n        plt.tight_layout()\n        plt.show()\n        print(f\"‚úÖ Plotted main and zoomed forecast views (last {self.zoom_bars} bars + full forecast) successfully! üöÄ\") # ‚úÖ log message\n    def make_predictions(self):\n        print(f\"The close data is:\")\n        print(self.close[0:10])\n        ctx_s, future_s = np.split(self.close, [-self.future_length])\n        quantiles, mean = model.forecast(ctx_s, prediction_length=self.prediction_length)\n        self.plot_forecast(ctx_s, quantiles[0], future_s)\n\n\n    def run_forecast(self):\n        \"\"\"Execute the full forecasting pipeline.\"\"\"\n        print(\"The deriv setting is \", self.DERIV_OR_YFINANCE) # üí¨ Log setting\n        if self.DERIV_OR_YFINANCE:\n            if self.load_deriv_data():\n                print(\"Loadded data from deriv\") # üí¨ Log data source\n            else:\n                print(\"‚ùå Failed to load deriv data. Exiting.\") # ‚ùå Log failure\n                return\n        else:\n            if self.load_data():\n                print(\"Loadded data from yfinance\") # üí¨ Log data source\n            else:\n                print(\"‚ùå Failed to load yfinance data. Exiting.\") # ‚ùå Log failure\n                return\n        print(\"***\"*10)\n        print(\"Startiing predictions\")\n        print(\"***\"*10)\n        self.make_predictions()\n     \n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:30:48.646269Z","iopub.execute_input":"2025-11-03T11:30:48.646649Z","iopub.status.idle":"2025-11-03T11:30:48.676035Z","shell.execute_reply.started":"2025-11-03T11:30:48.646626Z","shell.execute_reply":"2025-11-03T11:30:48.674562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Run all forecasts function","metadata":{}},{"cell_type":"code","source":"from typing import List\n\ndef run_all_stock_forecasts(ticker:str, start_date:str, end_date:str, zoom_bars=50, prediction_length=64, future_length=70, deriv:bool=False, count:int=5000,tf:int=60):\n    \"\"\"\n    Runs a single stock price forecasting model instance (ResNLS) \n    and instructs it to run backtests for all thresholds provided.\n    \"\"\"\n \n   \n\n    # ‚öôÔ∏è Prepare keyword arguments\n    kwargs = {\n        'zoom_bars': zoom_bars,\n        'prediction_length': prediction_length,\n        'future_length': future_length,\n        'deriv':deriv,\n        'count':count,\n        'tf':tf\n    }\n    \n    try:\n        # üåü Create the forecaster instance - Pass the entire list\n        forecaster = TiREXModel(\n            ticker,        # 1st POSITIONAL ARGUMENT\n            start_date,    # 2nd POSITIONAL ARGUMENT\n            end_date,      # 3rd POSITIONAL ARGUMENT\n            **kwargs,      # Remaining fixed keyword arguments\n         \n        )\n        \n        # üèÉ Run the forecast (trains once, backtests all thresholds)\n        forecaster.run_forecast()\n        print(f\"‚úÖ Run completed successfully.\")\n        \n    except NameError as e:\n        print(f\"‚ùå Error in RUN: Forecaster class not found. Check imports. Details: {e}\")\n    except Exception as e:\n        print(f\"üíî Error during execution (Model:): {e}\") # üíî\n        \n    print(\"\\nüéâ All stock forecast runs concluded.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:30:51.652748Z","iopub.execute_input":"2025-11-03T11:30:51.653101Z","iopub.status.idle":"2025-11-03T11:30:51.661931Z","shell.execute_reply.started":"2025-11-03T11:30:51.653077Z","shell.execute_reply":"2025-11-03T11:30:51.660639Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cover all the 'n' input lengths","metadata":{}},{"cell_type":"code","source":"# üî¢ Define the different sequence lengths (N_INPUT) to test\n\n\n   \ndef all_n_forecasts(ticker:str, start_date:str=\"2012-01-01\", end_date:str=\"2025-12-31\", zoom_bars=50, prediction_length=100, future_length=70, deriv:bool=False, count:int=5000,tf:int=60):\n    \"\"\"\n    Runs a comprehensive set of stock forecasts for a given ticker \n    by iterating over various sequence input lengths (N_INPUT).\n\n    Args:\n        ticker (str): The stock ticker symbol (e.g., 'AAPL').\n        start_date (str): The start date for historical data (e.g., '2012-01-01').\n        end_date (str): The end date for historical data (e.g., '2025-12-31').\n    \"\"\"\n    print(f\"üî• Starting all N-input forecast experiments for Ticker: {ticker}...\")\n\n    run_all_stock_forecasts(\n        ticker=ticker, \n        start_date=start_date,  # üóìÔ∏è Using the hardcoded start date\n        end_date=end_date,\n        zoom_bars=zoom_bars,    # üóìÔ∏è Using the hardcoded end date\n        prediction_length=prediction_length,    # üîó Passing the current N_INPUT\n        future_length=future_length,\n        deriv=deriv,\n        count=count,\n        tf=tf\n    )\n\n\n    # # üîÑ Loop through each defined input length\n    # for i, input_len in enumerate(input_lengths):\n    #     print(\"\\n\" + \"‚úÖ \"*90)\n    #     print(f\"üöÄ Running experiment {i+1}/{len(input_lengths)} with N_INPUT = {input_len}\")\n    #     print(\"‚úÖ \"*90)\n        \n    #     # üèÉ Execute the core forecasting function with the current input length\n    #     # NOTE: The provided code hardcodes the dates to \"2012-01-01\" and \"2025-12-31\" \n    #     # inside the loop, overriding the function arguments 'start_date' and 'end_date'.\n    #     run_all_stock_forecasts(\n    #         ticker=ticker, \n    #         start_date=start_date,  # üóìÔ∏è Using the hardcoded start date\n    #         end_date=end_date,\n    #         zoom_bars=zoom_bars,    # üóìÔ∏è Using the hardcoded end date\n    #         prediction_length=prediction_length,    # üîó Passing the current N_INPUT\n    #         future_length=future_length,\n    #         deriv=deriv,\n    #         count=count,\n    #         tf=tf\n    #     )\n        \n    #     print(f\"‚úÖ Finished run for N_INPUT = {input_len}.\")\n        \n    print(f\"\\nüéâ All N-input forecast sweeps completed for {ticker}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:31:26.845487Z","iopub.execute_input":"2025-11-03T11:31:26.845844Z","iopub.status.idle":"2025-11-03T11:31:26.854491Z","shell.execute_reply.started":"2025-11-03T11:31:26.845823Z","shell.execute_reply":"2025-11-03T11:31:26.853055Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# APPLE","metadata":{}},{"cell_type":"code","source":"all_n_forecasts('AAPL')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:31:28.982422Z","iopub.execute_input":"2025-11-03T11:31:28.982753Z","iopub.status.idle":"2025-11-03T11:31:32.363511Z","shell.execute_reply.started":"2025-11-03T11:31:28.982730Z","shell.execute_reply":"2025-11-03T11:31:32.362063Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GOOGLE","metadata":{}},{"cell_type":"code","source":"all_n_forecasts('GOOGL')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:31:38.888572Z","iopub.execute_input":"2025-11-03T11:31:38.888937Z","iopub.status.idle":"2025-11-03T11:31:42.217631Z","shell.execute_reply.started":"2025-11-03T11:31:38.888909Z","shell.execute_reply":"2025-11-03T11:31:42.216444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# AMAZON","metadata":{}},{"cell_type":"code","source":"all_n_forecasts('AMZN')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:31:42.219509Z","iopub.execute_input":"2025-11-03T11:31:42.219885Z","iopub.status.idle":"2025-11-03T11:31:45.458671Z","shell.execute_reply.started":"2025-11-03T11:31:42.219848Z","shell.execute_reply":"2025-11-03T11:31:45.457493Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MICROSOFT","metadata":{}},{"cell_type":"code","source":"all_n_forecasts('MSFT')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:31:45.460143Z","iopub.execute_input":"2025-11-03T11:31:45.460534Z","iopub.status.idle":"2025-11-03T11:31:48.797175Z","shell.execute_reply.started":"2025-11-03T11:31:45.460507Z","shell.execute_reply":"2025-11-03T11:31:48.796154Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EURUSD","metadata":{}},{"cell_type":"code","source":"\nTICKER = 'EURUSD=X'\nall_n_forecasts(TICKER)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:31:48.799315Z","iopub.execute_input":"2025-11-03T11:31:48.799638Z","iopub.status.idle":"2025-11-03T11:31:52.001628Z","shell.execute_reply.started":"2025-11-03T11:31:48.799615Z","shell.execute_reply":"2025-11-03T11:31:52.000388Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GBPUSD","metadata":{}},{"cell_type":"code","source":"TICKER = 'GBPUSD=X'\nall_n_forecasts(TICKER)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:31:52.002705Z","iopub.execute_input":"2025-11-03T11:31:52.003428Z","iopub.status.idle":"2025-11-03T11:31:55.422183Z","shell.execute_reply.started":"2025-11-03T11:31:52.003392Z","shell.execute_reply":"2025-11-03T11:31:55.421114Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# USDJPY","metadata":{}},{"cell_type":"code","source":"TICKER = 'USDJPY=X'\nall_n_forecasts(TICKER)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:31:55.423730Z","iopub.execute_input":"2025-11-03T11:31:55.424146Z","iopub.status.idle":"2025-11-03T11:31:58.713320Z","shell.execute_reply.started":"2025-11-03T11:31:55.424113Z","shell.execute_reply":"2025-11-03T11:31:58.712135Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# BTC-USD","metadata":{}},{"cell_type":"code","source":"TICKER = 'BTC-USD'\nall_n_forecasts(TICKER)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:31:58.714466Z","iopub.execute_input":"2025-11-03T11:31:58.714770Z","iopub.status.idle":"2025-11-03T11:32:02.102008Z","shell.execute_reply.started":"2025-11-03T11:31:58.714745Z","shell.execute_reply":"2025-11-03T11:32:02.100746Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ETH USD","metadata":{}},{"cell_type":"code","source":"TICKER = 'ETH-USD'\nall_n_forecasts(TICKER)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:32:02.103696Z","iopub.execute_input":"2025-11-03T11:32:02.104489Z","iopub.status.idle":"2025-11-03T11:32:05.811583Z","shell.execute_reply.started":"2025-11-03T11:32:02.104460Z","shell.execute_reply":"2025-11-03T11:32:05.810429Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SOL USD","metadata":{}},{"cell_type":"code","source":"TICKER = 'SOL-USD'\nall_n_forecasts(TICKER)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:32:05.812611Z","iopub.execute_input":"2025-11-03T11:32:05.812880Z","iopub.status.idle":"2025-11-03T11:32:09.165720Z","shell.execute_reply.started":"2025-11-03T11:32:05.812861Z","shell.execute_reply":"2025-11-03T11:32:09.164442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Deriv Volatility 10 Index","metadata":{}},{"cell_type":"code","source":"DERIV_SYMBOL = \"R_10\"         # üìà Volatility 100 Index (VIX equivalent)\nOHLC_GRANULARITY = 60       # üìÖ 1 Day in seconds (to mimic daily close data)\nOHLC_COUNT = 5000              # üíæ Number of historical daily candles to fetch\n\n# all_n_forecasts(ticker=DERIV_SYMBOL, start_date=\"2012-01-01\", end_date=\"2025-12-31\",threshold_list=[None, 0.001, 0.005, 0.01],deriv=True, count=OHLC_COUNT,tf=OHLC_GRANULARITY)\n\nall_n_forecasts(DERIV_SYMBOL, \"2012-01-01\", \"2025-12-31\", 50, 100, 70, True, 5000,60)\n      ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T11:35:29.290708Z","iopub.execute_input":"2025-11-03T11:35:29.291064Z","iopub.status.idle":"2025-11-03T11:35:29.756288Z","shell.execute_reply.started":"2025-11-03T11:35:29.291037Z","shell.execute_reply":"2025-11-03T11:35:29.754928Z"}},"outputs":[],"execution_count":null}]}